{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1__ZS26oWRg2o8AJFKZBqmRLKz36MIMu4","timestamp":1695093702468}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1-1: Affine Functions with 1 Feature"],"metadata":{"id":"HJMpaDSjhiAB"}},{"cell_type":"markdown","source":["### Code.1-1-1:Affine Function"],"metadata":{"id":"F4Po0Mtch3-3"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","from tensorflow.keras.layers import Dense\n","\n","# input : 하나의 feature라도 matrix 형태로 입력\n","x = tf.constant([[10.]])\n","# print(x.shape)   # 1x1\n","\n","# x = tf.constant([[10.], [20.]])\n","# print(x.shape)    # 2x1\n","\n","# dense layer (affine function)\n","dense = Dense(units = 1, activation='linear')\n","y_tf = dense(x)    # forward propagation + params initialization (실행마다 값이 다름. random parameter)\n","\n","# get weight and bias\n","W, b = dense.get_weights()\n","\n","# 행렬곱\n","y_man = tf.linalg.matmul(x, W) + b\n","\n","# print results\n","print(\"==== Input/Weight/Bias ====\")\n","print(\"x: {}\\n{}\\n\".format(x.shape, x.numpy()))\n","print(\"W: {}\\n{}\\n\".format(W.shape, W))\n","print(\"b: {}\\n{}\\n\".format(b.shape, b))\n","\n","print(\"====Output====\")\n","print(\"y(Tensorflow): {}\\n{}\\n\".format(y_tf.shape, y_tf.numpy()))\n","print(\"y(Manual): {}\\n{}\\n\".format(y_man.shape, y_man.numpy()))"],"metadata":{"id":"rD3Tf0bbitae","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692793299891,"user_tz":-540,"elapsed":4,"user":{"displayName":"규리YGR_","userId":"07280919293761396994"}},"outputId":"51e110f1-7ef5-434d-f7cb-e6b7505dd321"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==== Input/Weight/Bias ====\n","x: (1, 1)\n","[[10.]]\n","\n","W: (1, 1)\n","[[1.6498946]]\n","\n","b: (1,)\n","[0.]\n","\n","====Output====\n","y(Tensorflow): (1, 1)\n","[[16.498945]]\n","\n","y(Manual): (1, 1)\n","[[16.498945]]\n","\n"]}]},{"cell_type":"markdown","source":["## Note\n","1. input은 matrix형태로 생성\n","2. unit 하나를 이용해서 affine function 하나를 수행\n","3. activation function = 생략 or 'linear'로 설정 = affine function을 거친 z 자체가 output이 됨."],"metadata":{"id":"GeGrm7VZWCwj"}},{"cell_type":"markdown","source":["### Code.1-1-2:Params Initialization"],"metadata":{"id":"3MlW1I-0iAvo"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.initializers import Constant   # 내가 원하는 상수로 파라미터 초기화\n","\n","# weight and bias setting\n","w, b = tf.constant(10.), tf.constant(20.)\n","\n","w_init, b_init = Constant(w), Constant(b)     # 초기화해주는 object를 인스턴스로 선언 (tensor값이 아님)\n","\n","print(w_init, b_init)"],"metadata":{"id":"sgYe1aeki2qy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692793594508,"user_tz":-540,"elapsed":5,"user":{"displayName":"규리YGR_","userId":"07280919293761396994"}},"outputId":"9456b412-3700-411e-a39e-325d343df345"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<keras.initializers.initializers.Constant object at 0x7d969f859120> <keras.initializers.initializers.Constant object at 0x7d969f85a800>\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.initializers import Constant   # 내가 원하는 상수로 파라미터 초기화\n","\n","x = tf.constant([[10.]])     # input setting\n","\n","# weight and bias setting\n","w, b = tf.constant(10.), tf.constant(20.)\n","\n","w_init, b_init = Constant(w), Constant(b)     # 초기화해주는 object를 인스턴스로 선언\n","\n","#\n","dense = Dense(units=1,\n","              activation='linear',\n","              kernel_initializer = w_init,\n","              bias_initializer=b_init)\n","\n","y_tf = dense(x)\n","\n","W, B = dense.get_weights()\n","\n","# print results\n","print(\"W: {}\\n{}\\n\".format(W.shape, W))\n","print(\"W: {}\\n{}\\n\".format(B.shape, B))\n","print(y_tf)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wdbte32WXdm5","executionInfo":{"status":"ok","timestamp":1692793930487,"user_tz":-540,"elapsed":3,"user":{"displayName":"규리YGR_","userId":"07280919293761396994"}},"outputId":"4615c2de-f006-42ae-d771-150446e2f961"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["W: (1, 1)\n","[[10.]]\n","\n","W: (1,)\n","[20.]\n","\n","tf.Tensor([[120.]], shape=(1, 1), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["# 1-2: Affine Functions with n Features"],"metadata":{"id":"eMZ6f9XriPhV"}},{"cell_type":"markdown","source":["### Code.1-2-1: Affine Functions with n Features"],"metadata":{"id":"8yFcVk3UilVw"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense\n","\n","# 균등분포\n","x = tf.random.uniform(shape=(1, 10), minval=0, maxval = 10)   # 데이터는 1개 features는 10개. default value : (0,1) 사이의 값\n","print(x.shape, '\\n', x)\n","\n","dense = Dense(units=1, activation='linear')\n","y_tf = dense(x)\n","W, B = dense.get_weights()\n","\n","y_man = tf.linalg.matmul(x, W) + B   # broadcasting 되고있음.\n","\n","# print results\n","print(\"==== Input/Weight/Bias ====\")\n","print(\"x: {}\\n{}\\n\".format(x.shape, x.numpy()))     # 1 x 10 Row Vector\n","print(\"W: {}\\n{}\\n\".format(W.shape, W))     # 10 x 1 Column Vector\n","print(\"B: {}\\n{}\\n\".format(B.shape, B))     # scalar\n","\n","print(\"==== Outputs ====\")\n","print(\"y(Tensorflow): {}\\n{}\\n\".format(y_tf.shape, y_tf.numpy()))\n","print(\"y(manual): {}\\n{}\\n\".format(y_man.shape, y_man.numpy()))\n","\n","print(tf.math.equal(y_tf, y_man))"],"metadata":{"id":"5lOtVfLei3k_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692794635361,"user_tz":-540,"elapsed":2,"user":{"displayName":"규리YGR_","userId":"07280919293761396994"}},"outputId":"e8cf4441-ad08-42cf-b12d-d6759563b129"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 10) \n"," tf.Tensor(\n","[[5.5196533 9.533964  0.5760932 0.7697964 9.92778   5.134696  6.5215864\n","  6.6457987 3.6749709 1.5754652]], shape=(1, 10), dtype=float32)\n","==== Input/Weight/Bias ====\n","x: (1, 10)\n","[[5.5196533 9.533964  0.5760932 0.7697964 9.92778   5.134696  6.5215864\n","  6.6457987 3.6749709 1.5754652]]\n","\n","W: (10, 1)\n","[[-0.6120627 ]\n"," [-0.41574422]\n"," [ 0.68283993]\n"," [ 0.47522372]\n"," [ 0.42027992]\n"," [ 0.6728582 ]\n"," [ 0.7359436 ]\n"," [ 0.7296887 ]\n"," [-0.26886886]\n"," [ 0.55917436]]\n","\n","B: (1,)\n","[0.]\n","\n","==== Outputs ====\n","y(Tensorflow): (1, 1)\n","[[10.586268]]\n","\n","y(manual): (1, 1)\n","[[10.586268]]\n","\n","tf.Tensor([[ True]], shape=(1, 1), dtype=bool)\n"]}]},{"cell_type":"markdown","source":["# 1-3: Activation Functions"],"metadata":{"id":"C4m4dvygzGXP"}},{"cell_type":"markdown","source":["### Code.1-3-1:Activaion Layers"],"metadata":{"id":"5bLOBgtYzFzR"}},{"cell_type":"markdown","source":["1. activation function만 만드는 방법\n","2. affine function + activation function 같이 만드는 방법"],"metadata":{"id":"A68A5Irdbr8Y"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","from tensorflow.keras.layers import Activation\n","from tensorflow.math import exp, maximum     # sigmoid, relu\n","\n","x = tf.random.normal(shape=(1,5))   # input setting (표준정규분포)\n","\n","# activation layer 선언\n","sigmoid = Activation('sigmoid')\n","tanh = Activation('tanh')\n","relu = Activation('relu')\n","\n","# forward propagation (tensorflow)\n","y_sigmoid_tf = sigmoid(x)\n","y_tanh_tf = tanh(x)\n","y_relu_tf = relu(x)\n","\n","# forward propagation (manual)\n","y_sigmoid_man = 1 / (1 + exp(-x))\n","y_tanh_man = (exp(x)-exp(-x)) / (exp(x)+exp(-x))\n","y_relu_man = maximum(0, x)\n","\n","# print results\n","print(\"x: {}\\n{}\\n\".format(x.shape, x.numpy()))\n","\n","print(\"Sigmoid(Tensorflow): {}\\n{}\\n\".format(y_sigmoid_tf.shape, y_sigmoid_tf.numpy()))\n","print(\"Sigmoid(Manual): {}\\n{}\\n\".format(y_sigmoid_man.shape, y_sigmoid_man.numpy()))\n","\n","print(\"Tanh(Tensorflow): {}\\n{}\\n\".format(y_tanh_tf.shape, y_tanh_tf.numpy()))\n","print(\"Tanh(Manual): {}\\n{}\\n\".format(y_tanh_man.shape, y_tanh_man.numpy()))\n","\n","print(\"ReLU(Tensorflow): {}\\n{}\\n\".format(y_relu_tf.shape, y_relu_tf.numpy()))\n","print(\"ReLU(Manual): {}\\n{}\\n\".format(y_relu_man.shape, y_relu_man.numpy()))\n"],"metadata":{"id":"WQPbEqnnz4rg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692795411524,"user_tz":-540,"elapsed":2,"user":{"displayName":"규리YGR_","userId":"07280919293761396994"}},"outputId":"e81781ec-78c8-4d08-a2bb-a2885a69c4fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x: (1, 5)\n","[[ 1.2139647  1.0962358 -1.517538   1.490235   0.192643 ]]\n","\n","Sigmoid(Tensorflow): (1, 5)\n","[[0.7709997  0.74955416 0.17982435 0.81611353 0.5480123 ]]\n","\n","Sigmoid(Manual): (1, 5)\n","[[0.7709997  0.7495541  0.17982435 0.81611353 0.5480123 ]]\n","\n","Tanh(Tensorflow): (1, 5)\n","[[ 0.8378649   0.7991428  -0.90826756  0.90336806  0.19029476]]\n","\n","Tanh(Manual): (1, 5)\n","[[ 0.8378648   0.79914284 -0.9082676   0.9033679   0.1902948 ]]\n","\n","ReLU(Tensorflow): (1, 5)\n","[[1.2139647 1.0962358 0.        1.490235  0.192643 ]]\n","\n","ReLU(Manual): (1, 5)\n","[[1.2139647 1.0962358 0.        1.490235  0.192643 ]]\n","\n"]}]},{"cell_type":"markdown","source":["### Code.1-3-2:Activation in Dense Layer"],"metadata":{"id":"bHCpKByVzFSX"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense\n","\n","x = tf.random.normal(shape=(1,5))   # input setting (표준정규분포)\n","\n","# imp. artificial neurons\n","dense_sigmoid = Dense(units=1, activation='sigmoid')\n","dense_tanh = Dense(units=1, activation='tanh')\n","dense_relu = Dense(units=1, activation='relu')\n","\n","# forward propagation\n","y_sigmoid = dense_sigmoid(x)\n","y_tanh = dense_tanh(x)\n","y_relu = dense_relu(x)\n","\n","# get_weights\n","\n","# print results\n","print(\"x : {}\\n{}\\n\".format(x.shape, x.numpy()))\n","print(\"AN with Sigmoid : {}\\n{}\\n\".format(y_sigmoid.shape, y_sigmoid.numpy()))\n","print(\"AN with Tanh : {}\\n{}\\n\".format(y_tanh.shape, y_tanh.numpy()))\n","print(\"AN with ReLU : {}\\n{}\\n\".format(y_relu.shape, y_relu.numpy()))"],"metadata":{"id":"qgInuv4C2nHl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692795775699,"user_tz":-540,"elapsed":2,"user":{"displayName":"규리YGR_","userId":"07280919293761396994"}},"outputId":"dae1f17e-973c-4e9a-b57f-2c8d8679504b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x : (1, 5)\n","[[-0.6227576   0.4088141   0.20009246  1.06027    -0.42903432]]\n","\n","AN with Sigmoid : (1, 1)\n","[[0.6387753]]\n","\n","AN with Tanh : (1, 1)\n","[[-0.47593927]]\n","\n","AN with ReLU : (1, 1)\n","[[0.6243026]]\n","\n"]}]},{"cell_type":"markdown","source":["# 1-4: Artificial Neurons"],"metadata":{"id":"Dox-URRVLj2W"}},{"cell_type":"markdown","source":["### Code.1-4-1:Artificial Neurons"],"metadata":{"id":"rrmC0Od0zgEQ"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense\n","from tensorflow.math import exp, maximum\n","\n","# activation = 'sigmoid'\n","# activation = 'tanh'\n","activation = 'relu'\n","\n","x = tf.random.uniform(shape=(1, 10))\n","\n","dense = Dense(units=1, activation=activation)  # imp. an affine + activation\n","\n","y_tf = dense(x)\n","W, B = dense.get_weights()\n","\n","# calculate activation value manually\n","y_man = tf.linalg.matmul(x, W) + B\n","if activation == 'sigmoid':\n","  y_man = 1 / (1 + exp(-y_man))\n","elif activation == 'tanh':\n","  y_man = (exp(y_man)-exp(-y_man)) / (exp(y_man)+exp(-y_man))\n","elif activation == 'relu':\n","  y_man = maximum(0, y_man)\n","\n","print(\"Activation : \", activation)\n","print(\"y_tf : {}\\n{}\\n\".format(y_tf.shape, y_tf.numpy()))\n","print(\"y_man : {}\\n{}\\n\".format(y_man.shape, y_man.numpy()))\n","print(tf.math.equal(y_tf, y_man))"],"metadata":{"id":"sr3V91746tcg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692796524720,"user_tz":-540,"elapsed":3,"user":{"displayName":"규리YGR_","userId":"07280919293761396994"}},"outputId":"8b06795e-82ab-4e3d-98e0-0b93f60e1386"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Activation :  relu\n","y_tf : (1, 1)\n","[[0.]]\n","\n","y_man : (1, 1)\n","[[0.]]\n","\n","tf.Tensor([[ True]], shape=(1, 1), dtype=bool)\n"]}]},{"cell_type":"markdown","source":["# 1-5: Minibatches"],"metadata":{"id":"Puhy9zGVLt-f"}},{"cell_type":"markdown","source":["### Code.1-5-1: Shapes of Dense Layers"],"metadata":{"id":"31MYNFLJzsgx"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense\n","\n","N, n_feature = 8, 10   # N : data의 개수, n_feature : feature의 개수\n","x = tf.random.normal(shape=(N, n_feature))\n","print(x.shape)\n","\n","dense = Dense(units = 1, activation='relu')    # imp. an AN\n","y = dense(x)\n","\n","W, B = dense.get_weights()\n","\n","# print results\n","print(\"Shape of x : {}\".format(x.shape))\n","print(\"Shape of W : {}\".format(W.shape))\n","print(\"Shape of B : {}\".format(B.shape))\n"],"metadata":{"id":"dFZfZVjg9Uy8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692796836279,"user_tz":-540,"elapsed":4,"user":{"displayName":"규리YGR_","userId":"07280919293761396994"}},"outputId":"75c247af-0bac-4cb4-d342-c5366cbb3ac4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(8, 10)\n","Shape of x : (8, 10)\n","Shape of W : (10, 1)\n","Shape of B : (1,)\n"]}]},{"cell_type":"markdown","source":["!주의! : Minibatch의 사이즈(데이터의 개수 N)은 절대 weight, bias shape에 영향을 안 미친다!"],"metadata":{"id":"R3mcXtnwjqEm"}},{"cell_type":"markdown","source":["### Code.1-5-2: Output calculations"],"metadata":{"id":"HKvNFf-Gzyfq"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense\n","\n","N, n_feature = 8, 10   # N : data의 개수, n_feature : feature의 개수\n","x = tf.random.normal(shape=(N, n_feature))\n","# print(x.shape)\n","\n","dense = Dense(units = 1, activation='relu')    # imp. an AN\n","y_tf = dense(x)     # forward propogation\n","\n","W, B = dense.get_weights()\n","\n","y_man = tf.linalg.matmul(x, W) + B     # forward propogation manually\n","y_man = maximum(0, y_man)\n","\n","# print results\n","print(\"Shape of x : {}\".format(x.shape))\n","print(\"Shape of W : {}\".format(W.shape))\n","print(\"Shape of B : {}\\n\".format(B.shape))\n","\n","print(\"Output (Tensorflow) : \\n{}\\n\".format(y_tf.numpy()))\n","print(\"Output (Manual) : \\n{}\\n\".format(y_man.numpy()))\n","print(tf.math.equal(y_tf, y_man))"],"metadata":{"id":"V1dGC5zv-WvK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692797214771,"user_tz":-540,"elapsed":633,"user":{"displayName":"규리YGR_","userId":"07280919293761396994"}},"outputId":"b0ea7acc-4881-4111-f9d8-e563d75b4a64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of x : (8, 10)\n","Shape of W : (10, 1)\n","Shape of B : (1,)\n","\n","Output (Tensorflow) : \n","[[0.7073164]\n"," [0.       ]\n"," [0.8786447]\n"," [0.       ]\n"," [1.7559942]\n"," [2.243993 ]\n"," [0.       ]\n"," [0.       ]]\n","\n","Output (Manual) : \n","[[0.7073164]\n"," [0.       ]\n"," [0.8786447]\n"," [0.       ]\n"," [1.7559942]\n"," [2.243993 ]\n"," [0.       ]\n"," [0.       ]]\n","\n","tf.Tensor(\n","[[ True]\n"," [ True]\n"," [ True]\n"," [ True]\n"," [ True]\n"," [ True]\n"," [ True]\n"," [ True]], shape=(8, 1), dtype=bool)\n"]}]},{"cell_type":"markdown","source":["## __3D Tensor의 계산__\n","\n","* Dense Layer는 2D tensor용으로 설계된 모델이다. <br>\n","* 3D tensor를 입력하기 위해서는 reshape를 통해서 2D tensor로 만들어줘야한다. <br>\n","* (batch_size, height, width) --> (batch_size, height*width)"],"metadata":{"id":"mpQBr7nwCnga"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# Example 3D tensor with shape (batch_size, height, width)\n","input_tensor_3d = tf.random.normal((32, 10, 20))  # Batch size: 32, Height: 10, Width: 20\n","\n","# Reshape the 3D tensor to a 2D tensor with shape (batch_size, height * width)\n","input_tensor_2d = tf.reshape(input_tensor_3d, (32, -1))  # -1 allows automatic calculation of the remaining dimension\n","\n","# Define a Dense layer\n","dense_layer = tf.keras.layers.Dense(units=64, activation='relu')\n","\n","# Apply the Dense layer to the reshaped 2D tensor\n","output = dense_layer(input_tensor_2d)"],"metadata":{"id":"hzbv1sIdEVjZ"},"execution_count":null,"outputs":[]}]}