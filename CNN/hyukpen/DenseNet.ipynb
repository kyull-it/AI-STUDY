{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5KpkD4h5YP6g"},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"code","source":["class Bottleneck(nn.Module):\n","    def __init__(self, in_channels, k):\n","        super().__init__()\n","\n","        self.residual = nn.Sequential(nn.BatchNorm2d(in_channels),\n","                                      nn.ReLU(inplace=True),\n","                                      nn.Conv2d(in_channels, 4*k, kernel_size=1, bias=False),\n","                                      nn.BatchNorm2d(4*k),\n","                                      nn.ReLU(inplace=True),\n","                                      nn.Conv2d(4*k, k, kernel_size=3, padding=1, bias=False))\n","\n","    def forward(self, x):\n","        return torch.cat([x, self.residual(x)], 1) # x가 바로 직전 채널 뿐만 아니라 그 전것도 모두 가지고 있음\n","\n","class Transition(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","\n","        self.transition = nn.Sequential(nn.BatchNorm2d(in_channels),\n","                                        nn.ReLU(inplace=True),\n","                                        nn.Conv2d(in_channels, out_channels, 1, bias=False),\n","                                        nn.AvgPool2d(2))\n","\n","    def forward(self, x):\n","        return self.transition(x)\n","\n","#DesneNet-BC\n","#B stands for bottleneck layer(BN-RELU-CONV(1x1)-BN-RELU-CONV(3x3))\n","#C stands for compression factor(0< theta ≤1)\n","class DenseNet(nn.Module):\n","    def __init__(self, num_block_list, growth_rate, reduction=0.5, num_class=100):\n","        super().__init__()\n","        self.k = growth_rate\n","\n","        inner_channels = 2 * self.k\n","\n","        self.conv1 = nn.Sequential(nn.Conv2d(3, inner_channels, kernel_size=7, stride=2, padding=3, bias=False),\n","                                   nn.BatchNorm2d(inner_channels),\n","                                   nn.ReLU(inplace=True),\n","                                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n","\n","        layers = []\n","        for num_blocks in num_block_list[:-1]:\n","            layers += [self.make_dense_block(inner_channels, num_blocks)]\n","            inner_channels +=  num_blocks * self.k\n","\n","            out_channels = int(reduction * inner_channels)\n","            layers += [Transition(inner_channels, out_channels)]\n","            inner_channels = out_channels\n","\n","        layers += [self.make_dense_block(inner_channels, num_block_list[-1])]\n","        inner_channels += num_block_list[-1] * self.k\n","\n","        layers += [nn.BatchNorm2d(inner_channels)]\n","        layers += [nn.ReLU(inplace=True)]\n","        self.features = nn.Sequential(*layers)\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.linear = nn.Linear(inner_channels, num_class)\n","\n","        # Official init from torch repo.\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, x):\n","        output = self.conv1(x)\n","        output = self.features(output)\n","        output = self.avgpool(output)\n","        output = torch.flatten(output, start_dim=1)\n","        output = self.linear(output)\n","        return output\n","\n","    def make_dense_block(self, in_channels, nblocks):\n","        dense_block = []\n","        for _ in range(nblocks):\n","            dense_block += [ Bottleneck(in_channels, self.k) ]\n","            in_channels += self.k\n","        return nn.Sequential(*dense_block)"],"metadata":{"id":"YdnBzj1sP6nm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def densenet121(**kwargs):\n","    return DenseNet([6,12,24,16], growth_rate=32, **kwargs)\n","\n","def densenet169(**kwargs):\n","    return DenseNet([6,12,32,32], growth_rate=32, **kwargs)\n","\n","def densenet201(**kwargs):\n","    return DenseNet([6,12,48,32], growth_rate=32, **kwargs)\n","\n","def densenet264(**kwargs):\n","    return DenseNet([6,12,64,48], growth_rate=32, **kwargs)"],"metadata":{"id":"cmcwkOJza33Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = densenet264()\n","# print(model)\n","!pip install torchinfo\n","from torchinfo import summary\n","summary(model, input_size=(2,3,224,224), device='cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Nu7lsL7a5mR","executionInfo":{"status":"ok","timestamp":1699011512006,"user_tz":-540,"elapsed":9270,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"5ff6fa61-ddf6-4260-ed97-dd8c35ebaa13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n"]},{"output_type":"execute_result","data":{"text/plain":["===============================================================================================\n","Layer (type:depth-idx)                        Output Shape              Param #\n","===============================================================================================\n","DenseNet                                      [2, 100]                  --\n","├─Sequential: 1-1                             [2, 64, 56, 56]           --\n","│    └─Conv2d: 2-1                            [2, 64, 112, 112]         9,408\n","│    └─BatchNorm2d: 2-2                       [2, 64, 112, 112]         128\n","│    └─ReLU: 2-3                              [2, 64, 112, 112]         --\n","│    └─MaxPool2d: 2-4                         [2, 64, 56, 56]           --\n","├─Sequential: 1-2                             [2, 2688, 7, 7]           --\n","│    └─Sequential: 2-5                        [2, 256, 56, 56]          --\n","│    │    └─Bottleneck: 3-1                   [2, 96, 56, 56]           45,440\n","│    │    └─Bottleneck: 3-2                   [2, 128, 56, 56]          49,600\n","│    │    └─Bottleneck: 3-3                   [2, 160, 56, 56]          53,760\n","│    │    └─Bottleneck: 3-4                   [2, 192, 56, 56]          57,920\n","│    │    └─Bottleneck: 3-5                   [2, 224, 56, 56]          62,080\n","│    │    └─Bottleneck: 3-6                   [2, 256, 56, 56]          66,240\n","│    └─Transition: 2-6                        [2, 128, 28, 28]          --\n","│    │    └─Sequential: 3-7                   [2, 128, 28, 28]          33,280\n","│    └─Sequential: 2-7                        [2, 512, 28, 28]          --\n","│    │    └─Bottleneck: 3-8                   [2, 160, 28, 28]          53,760\n","│    │    └─Bottleneck: 3-9                   [2, 192, 28, 28]          57,920\n","│    │    └─Bottleneck: 3-10                  [2, 224, 28, 28]          62,080\n","│    │    └─Bottleneck: 3-11                  [2, 256, 28, 28]          66,240\n","│    │    └─Bottleneck: 3-12                  [2, 288, 28, 28]          70,400\n","│    │    └─Bottleneck: 3-13                  [2, 320, 28, 28]          74,560\n","│    │    └─Bottleneck: 3-14                  [2, 352, 28, 28]          78,720\n","│    │    └─Bottleneck: 3-15                  [2, 384, 28, 28]          82,880\n","│    │    └─Bottleneck: 3-16                  [2, 416, 28, 28]          87,040\n","│    │    └─Bottleneck: 3-17                  [2, 448, 28, 28]          91,200\n","│    │    └─Bottleneck: 3-18                  [2, 480, 28, 28]          95,360\n","│    │    └─Bottleneck: 3-19                  [2, 512, 28, 28]          99,520\n","│    └─Transition: 2-8                        [2, 256, 14, 14]          --\n","│    │    └─Sequential: 3-20                  [2, 256, 14, 14]          132,096\n","│    └─Sequential: 2-9                        [2, 2304, 14, 14]         --\n","│    │    └─Bottleneck: 3-21                  [2, 288, 14, 14]          70,400\n","│    │    └─Bottleneck: 3-22                  [2, 320, 14, 14]          74,560\n","│    │    └─Bottleneck: 3-23                  [2, 352, 14, 14]          78,720\n","│    │    └─Bottleneck: 3-24                  [2, 384, 14, 14]          82,880\n","│    │    └─Bottleneck: 3-25                  [2, 416, 14, 14]          87,040\n","│    │    └─Bottleneck: 3-26                  [2, 448, 14, 14]          91,200\n","│    │    └─Bottleneck: 3-27                  [2, 480, 14, 14]          95,360\n","│    │    └─Bottleneck: 3-28                  [2, 512, 14, 14]          99,520\n","│    │    └─Bottleneck: 3-29                  [2, 544, 14, 14]          103,680\n","│    │    └─Bottleneck: 3-30                  [2, 576, 14, 14]          107,840\n","│    │    └─Bottleneck: 3-31                  [2, 608, 14, 14]          112,000\n","│    │    └─Bottleneck: 3-32                  [2, 640, 14, 14]          116,160\n","│    │    └─Bottleneck: 3-33                  [2, 672, 14, 14]          120,320\n","│    │    └─Bottleneck: 3-34                  [2, 704, 14, 14]          124,480\n","│    │    └─Bottleneck: 3-35                  [2, 736, 14, 14]          128,640\n","│    │    └─Bottleneck: 3-36                  [2, 768, 14, 14]          132,800\n","│    │    └─Bottleneck: 3-37                  [2, 800, 14, 14]          136,960\n","│    │    └─Bottleneck: 3-38                  [2, 832, 14, 14]          141,120\n","│    │    └─Bottleneck: 3-39                  [2, 864, 14, 14]          145,280\n","│    │    └─Bottleneck: 3-40                  [2, 896, 14, 14]          149,440\n","│    │    └─Bottleneck: 3-41                  [2, 928, 14, 14]          153,600\n","│    │    └─Bottleneck: 3-42                  [2, 960, 14, 14]          157,760\n","│    │    └─Bottleneck: 3-43                  [2, 992, 14, 14]          161,920\n","│    │    └─Bottleneck: 3-44                  [2, 1024, 14, 14]         166,080\n","│    │    └─Bottleneck: 3-45                  [2, 1056, 14, 14]         170,240\n","│    │    └─Bottleneck: 3-46                  [2, 1088, 14, 14]         174,400\n","│    │    └─Bottleneck: 3-47                  [2, 1120, 14, 14]         178,560\n","│    │    └─Bottleneck: 3-48                  [2, 1152, 14, 14]         182,720\n","│    │    └─Bottleneck: 3-49                  [2, 1184, 14, 14]         186,880\n","│    │    └─Bottleneck: 3-50                  [2, 1216, 14, 14]         191,040\n","│    │    └─Bottleneck: 3-51                  [2, 1248, 14, 14]         195,200\n","│    │    └─Bottleneck: 3-52                  [2, 1280, 14, 14]         199,360\n","│    │    └─Bottleneck: 3-53                  [2, 1312, 14, 14]         203,520\n","│    │    └─Bottleneck: 3-54                  [2, 1344, 14, 14]         207,680\n","│    │    └─Bottleneck: 3-55                  [2, 1376, 14, 14]         211,840\n","│    │    └─Bottleneck: 3-56                  [2, 1408, 14, 14]         216,000\n","│    │    └─Bottleneck: 3-57                  [2, 1440, 14, 14]         220,160\n","│    │    └─Bottleneck: 3-58                  [2, 1472, 14, 14]         224,320\n","│    │    └─Bottleneck: 3-59                  [2, 1504, 14, 14]         228,480\n","│    │    └─Bottleneck: 3-60                  [2, 1536, 14, 14]         232,640\n","│    │    └─Bottleneck: 3-61                  [2, 1568, 14, 14]         236,800\n","│    │    └─Bottleneck: 3-62                  [2, 1600, 14, 14]         240,960\n","│    │    └─Bottleneck: 3-63                  [2, 1632, 14, 14]         245,120\n","│    │    └─Bottleneck: 3-64                  [2, 1664, 14, 14]         249,280\n","│    │    └─Bottleneck: 3-65                  [2, 1696, 14, 14]         253,440\n","│    │    └─Bottleneck: 3-66                  [2, 1728, 14, 14]         257,600\n","│    │    └─Bottleneck: 3-67                  [2, 1760, 14, 14]         261,760\n","│    │    └─Bottleneck: 3-68                  [2, 1792, 14, 14]         265,920\n","│    │    └─Bottleneck: 3-69                  [2, 1824, 14, 14]         270,080\n","│    │    └─Bottleneck: 3-70                  [2, 1856, 14, 14]         274,240\n","│    │    └─Bottleneck: 3-71                  [2, 1888, 14, 14]         278,400\n","│    │    └─Bottleneck: 3-72                  [2, 1920, 14, 14]         282,560\n","│    │    └─Bottleneck: 3-73                  [2, 1952, 14, 14]         286,720\n","│    │    └─Bottleneck: 3-74                  [2, 1984, 14, 14]         290,880\n","│    │    └─Bottleneck: 3-75                  [2, 2016, 14, 14]         295,040\n","│    │    └─Bottleneck: 3-76                  [2, 2048, 14, 14]         299,200\n","│    │    └─Bottleneck: 3-77                  [2, 2080, 14, 14]         303,360\n","│    │    └─Bottleneck: 3-78                  [2, 2112, 14, 14]         307,520\n","│    │    └─Bottleneck: 3-79                  [2, 2144, 14, 14]         311,680\n","│    │    └─Bottleneck: 3-80                  [2, 2176, 14, 14]         315,840\n","│    │    └─Bottleneck: 3-81                  [2, 2208, 14, 14]         320,000\n","│    │    └─Bottleneck: 3-82                  [2, 2240, 14, 14]         324,160\n","│    │    └─Bottleneck: 3-83                  [2, 2272, 14, 14]         328,320\n","│    │    └─Bottleneck: 3-84                  [2, 2304, 14, 14]         332,480\n","│    └─Transition: 2-10                       [2, 1152, 7, 7]           --\n","│    │    └─Sequential: 3-85                  [2, 1152, 7, 7]           2,658,816\n","│    └─Sequential: 2-11                       [2, 2688, 7, 7]           --\n","│    │    └─Bottleneck: 3-86                  [2, 1184, 7, 7]           186,880\n","│    │    └─Bottleneck: 3-87                  [2, 1216, 7, 7]           191,040\n","│    │    └─Bottleneck: 3-88                  [2, 1248, 7, 7]           195,200\n","│    │    └─Bottleneck: 3-89                  [2, 1280, 7, 7]           199,360\n","│    │    └─Bottleneck: 3-90                  [2, 1312, 7, 7]           203,520\n","│    │    └─Bottleneck: 3-91                  [2, 1344, 7, 7]           207,680\n","│    │    └─Bottleneck: 3-92                  [2, 1376, 7, 7]           211,840\n","│    │    └─Bottleneck: 3-93                  [2, 1408, 7, 7]           216,000\n","│    │    └─Bottleneck: 3-94                  [2, 1440, 7, 7]           220,160\n","│    │    └─Bottleneck: 3-95                  [2, 1472, 7, 7]           224,320\n","│    │    └─Bottleneck: 3-96                  [2, 1504, 7, 7]           228,480\n","│    │    └─Bottleneck: 3-97                  [2, 1536, 7, 7]           232,640\n","│    │    └─Bottleneck: 3-98                  [2, 1568, 7, 7]           236,800\n","│    │    └─Bottleneck: 3-99                  [2, 1600, 7, 7]           240,960\n","│    │    └─Bottleneck: 3-100                 [2, 1632, 7, 7]           245,120\n","│    │    └─Bottleneck: 3-101                 [2, 1664, 7, 7]           249,280\n","│    │    └─Bottleneck: 3-102                 [2, 1696, 7, 7]           253,440\n","│    │    └─Bottleneck: 3-103                 [2, 1728, 7, 7]           257,600\n","│    │    └─Bottleneck: 3-104                 [2, 1760, 7, 7]           261,760\n","│    │    └─Bottleneck: 3-105                 [2, 1792, 7, 7]           265,920\n","│    │    └─Bottleneck: 3-106                 [2, 1824, 7, 7]           270,080\n","│    │    └─Bottleneck: 3-107                 [2, 1856, 7, 7]           274,240\n","│    │    └─Bottleneck: 3-108                 [2, 1888, 7, 7]           278,400\n","│    │    └─Bottleneck: 3-109                 [2, 1920, 7, 7]           282,560\n","│    │    └─Bottleneck: 3-110                 [2, 1952, 7, 7]           286,720\n","│    │    └─Bottleneck: 3-111                 [2, 1984, 7, 7]           290,880\n","│    │    └─Bottleneck: 3-112                 [2, 2016, 7, 7]           295,040\n","│    │    └─Bottleneck: 3-113                 [2, 2048, 7, 7]           299,200\n","│    │    └─Bottleneck: 3-114                 [2, 2080, 7, 7]           303,360\n","│    │    └─Bottleneck: 3-115                 [2, 2112, 7, 7]           307,520\n","│    │    └─Bottleneck: 3-116                 [2, 2144, 7, 7]           311,680\n","│    │    └─Bottleneck: 3-117                 [2, 2176, 7, 7]           315,840\n","│    │    └─Bottleneck: 3-118                 [2, 2208, 7, 7]           320,000\n","│    │    └─Bottleneck: 3-119                 [2, 2240, 7, 7]           324,160\n","│    │    └─Bottleneck: 3-120                 [2, 2272, 7, 7]           328,320\n","│    │    └─Bottleneck: 3-121                 [2, 2304, 7, 7]           332,480\n","│    │    └─Bottleneck: 3-122                 [2, 2336, 7, 7]           336,640\n","│    │    └─Bottleneck: 3-123                 [2, 2368, 7, 7]           340,800\n","│    │    └─Bottleneck: 3-124                 [2, 2400, 7, 7]           344,960\n","│    │    └─Bottleneck: 3-125                 [2, 2432, 7, 7]           349,120\n","│    │    └─Bottleneck: 3-126                 [2, 2464, 7, 7]           353,280\n","│    │    └─Bottleneck: 3-127                 [2, 2496, 7, 7]           357,440\n","│    │    └─Bottleneck: 3-128                 [2, 2528, 7, 7]           361,600\n","│    │    └─Bottleneck: 3-129                 [2, 2560, 7, 7]           365,760\n","│    │    └─Bottleneck: 3-130                 [2, 2592, 7, 7]           369,920\n","│    │    └─Bottleneck: 3-131                 [2, 2624, 7, 7]           374,080\n","│    │    └─Bottleneck: 3-132                 [2, 2656, 7, 7]           378,240\n","│    │    └─Bottleneck: 3-133                 [2, 2688, 7, 7]           382,400\n","│    └─BatchNorm2d: 2-12                      [2, 2688, 7, 7]           5,376\n","│    └─ReLU: 2-13                             [2, 2688, 7, 7]           --\n","├─AdaptiveAvgPool2d: 1-3                      [2, 2688, 1, 1]           --\n","├─Linear: 1-4                                 [2, 100]                  268,900\n","===============================================================================================\n","Total params: 30,917,604\n","Trainable params: 30,917,604\n","Non-trainable params: 0\n","Total mult-adds (G): 11.50\n","===============================================================================================\n","Input size (MB): 1.20\n","Forward/backward pass size (MB): 680.69\n","Params size (MB): 123.67\n","Estimated Total Size (MB): 805.56\n","==============================================================================================="]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["x = torch.randn(2,3,224,224)\n","print(model(x).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UUbJ0Urfa8-J","executionInfo":{"status":"ok","timestamp":1699011513535,"user_tz":-540,"elapsed":1542,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"5b7352b3-effb-4819-ac81-8d5ec6aa099b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 100])\n"]}]}]}